{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from itertools import combinations, product\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from queue import LifoQueue\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    DATA_PATH = r'parus_results'\n",
    "    files = os.listdir(DATA_PATH)\n",
    "    trees_df = pd.DataFrame(columns=['id', 'form', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel'])\n",
    "\n",
    "    for file in files:\n",
    "        full_dir = os.path.join(DATA_PATH, file)\n",
    "        name = file.split('.')[0]\n",
    "        with open(full_dir, encoding='utf-8') as f:\n",
    "            this_df = pd.read_csv(f, sep='\\t',\n",
    "                                  names=['id', 'form', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel'])\n",
    "            if this_df['id'].duplicated().any():\n",
    "                start_of_subtree_df = list(this_df.groupby(this_df.id).get_group(1).index)\n",
    "                boundaries = start_of_subtree_df + [max(list(this_df.index)) + 1]\n",
    "                list_of_dfs = [this_df.iloc[boundaries[n]:boundaries[n + 1]] for n in range(len(boundaries) - 1)]\n",
    "                local_counter = 1\n",
    "                for df in list_of_dfs:\n",
    "                    df['sent_name'] = name + '_' + str(local_counter)\n",
    "                    trees_df = pd.concat([trees_df, df], ignore_index=True)\n",
    "                    local_counter += 1\n",
    "            else:\n",
    "                this_df['sent_name'] = name\n",
    "                trees_df = pd.concat([trees_df, this_df], ignore_index=True)\n",
    "\n",
    "    # delete useless data\n",
    "    trees_df = trees_df.drop(columns=['upostag', 'xpostag', 'feats'], axis=1)\n",
    "    trees_df.drop(index=[11067], inplace=True)\n",
    "    trees_df.loc[13742, 'deprel'] = 'разъяснит'\n",
    "\n",
    "    # delete relations of type PUNC and reindex\n",
    "    trees_df_filtered = trees_df[trees_df.deprel != 'PUNC']\n",
    "    trees_df_filtered = trees_df_filtered.reset_index(drop=True)\n",
    "    trees_df_filtered.index = trees_df_filtered.index + 1\n",
    "    return trees_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec(trees_df_filtered, lemmas):\n",
    "    lemma_sent_df = trees_df_filtered[['lemma', 'sent_name']]\n",
    "    lemma_sent_dict = {}\n",
    "    for name, group in lemma_sent_df.groupby('sent_name'):\n",
    "        lemma_sent_dict[name] = []\n",
    "        for _, row in group.iterrows():\n",
    "            lemma_sent_dict[name].append(row['lemma'])\n",
    "    model = Word2Vec(list(lemma_sent_dict.values()), min_count=1)\n",
    "    similar_dict = {}\n",
    "    for lemma in lemmas:\n",
    "        similar_dict[lemma] = model.most_similar(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, id, lemma=None, form=None, sent_name=None, is_included=False):\n",
    "        self.id = id\n",
    "        self.lemma = lemma\n",
    "        self.form = form\n",
    "        self.sent_name = sent_name\n",
    "        self.is_included = is_included\n",
    "\n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, node_id_from, node_id_to, weight):\n",
    "        self.node_from = node_id_from\n",
    "        self.node_to = node_id_to\n",
    "        self.weight = weight  # relation type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.edges = []\n",
    "        self.nodes = []\n",
    "        # self.heights = []\n",
    "        self.inactive = set()\n",
    "        self.created = set()\n",
    "        self.heights = {}\n",
    "        self.edges_dict_from = {}\n",
    "        self.edges_dict_to = {}\n",
    "        self.nodes_dict_id = {}\n",
    "\n",
    "    def set_help_dict(self):\n",
    "        self.edges_dict_from = {k: list(v) for k, v in itertools.groupby(sorted(self.edges, key=lambda x: x.node_from),\n",
    "                                                                         key=lambda x: x.node_from)}\n",
    "        self.nodes_dict_id = {node.id: node for node in self.nodes}\n",
    "        self.edges_dict_to = {k: list(v) for k, v in itertools.groupby(self.edges, key=lambda x: x.node_to)}\n",
    "\n",
    "    def add_node(self, node):\n",
    "        self.nodes.append(node)\n",
    "\n",
    "    def add_edge(self, edge):\n",
    "        self.edges.append(edge)\n",
    "\n",
    "    def get_node(self, node_id):\n",
    "        return self.nodes_dict_id.get(node_id)  # return Node class instance\n",
    "\n",
    "    def get_children(self, node_id):\n",
    "        edges = self.edges_dict_from.get(node_id)\n",
    "        # only_active = list(filter(lambda edge: edge.node_to not in self.inactive and edge.node_from not in self.inactive, edges if edges is not None else []))\n",
    "        # return list(map(lambda x: x.node_to, only_active if only_active is not None else []))\n",
    "        return set(map(lambda x: x.node_to, edges if edges is not None else []))\n",
    "\n",
    "    def get_edge(self, to_id):\n",
    "        return self.edges_dict_to.get(to_id)\n",
    "\n",
    "    def remove_edge(self, to_id):\n",
    "        self.edges = list(filter(lambda x: x.node_to != to_id, self.edges))\n",
    "\n",
    "    def copy_node_details(self, existing_node):\n",
    "        new_node = Node(id=len(self.nodes),\n",
    "                    form=existing_node.form,\n",
    "                    sent_name=existing_node.sent_name,\n",
    "                    is_included=existing_node.is_included)\n",
    "        self.nodes_dict_id[new_node.id] = new_node\n",
    "        self.created.add(new_node.id)\n",
    "        return new_node\n",
    "\n",
    "    def add_new_edges(self, new_node_id, children):\n",
    "        for child_id in children:\n",
    "            new_edge = Edge(new_node_id, child_id, self.get_edge(child_id)[0].weight)\n",
    "            if child_id in self.edges_dict_to.keys():\n",
    "                self.edges_dict_to[child_id].append(new_edge)\n",
    "            else:\n",
    "                self.edges_dict_to[child_id] = [new_edge]\n",
    "            self.edges.append(new_edge)\n",
    "            if new_node_id in self.edges_dict_from.keys():\n",
    "                self.edges_dict_from[new_node_id].append(new_edge)\n",
    "            else:\n",
    "                self.edges_dict_from[new_node_id] = [new_edge]\n",
    "\n",
    "    def add_edge_to_dict(self, edge):\n",
    "        self.edges_dict_to[edge.node_to] = [edge]\n",
    "        if edge.node_from in self.edges_dict_from.keys():\n",
    "            self.edges_dict_from[edge.node_from].append(edge)\n",
    "        else:\n",
    "            self.edges_dict_from[edge.node_from] = edge\n",
    "        self.edges.append(edge)\n",
    "\n",
    "    def add_node_to_dict(self, node):\n",
    "        self.nodes_dict_id[node.id] = node\n",
    "        self.nodes.append(node)\n",
    "\n",
    "    def add_inactive(self, node_id):\n",
    "        self.inactive.add(node_id)\n",
    "        \n",
    "    def calculate_heights(self):\n",
    "        visited = np.full(len(self.nodes), False, dtype=bool)\n",
    "        # self.heights = np.full(len(self.nodes), -1, dtype=int)  # all heights are -1 initially\n",
    "        stack = LifoQueue()\n",
    "        stack.put(0)\n",
    "        prev = None\n",
    "        while stack.qsize() > 0:\n",
    "            curr = stack.get()\n",
    "            stack.put(curr)\n",
    "            if not visited[curr]:\n",
    "                visited[curr] = True\n",
    "            children = self.get_children(curr)\n",
    "            if len(children) == 0:\n",
    "                self.heights[curr] = [0]\n",
    "                prev = curr\n",
    "                stack.get()\n",
    "            else:\n",
    "                all_visited_flag = True\n",
    "                for child in children:\n",
    "                    if not visited[child]:\n",
    "                        all_visited_flag = False\n",
    "                        stack.put(child)\n",
    "                if all_visited_flag:\n",
    "                    curr_height = []\n",
    "                    if len(children) > 1:\n",
    "                        for child in children:\n",
    "                            for child_height in self.heights[child]:\n",
    "                                curr_height.append(child_height + 1)\n",
    "                    else:\n",
    "                        curr_height = [h + 1 for h in self.heights[prev]]\n",
    "                    self.heights[curr] = list(set(curr_height))\n",
    "                    prev = curr\n",
    "                    stack.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_tree(trees_df_filtered, dict_lemmas, dict_rel):\n",
    "    # construct a tree with a list of edges and a list of nodes\n",
    "    whole_tree = Tree()\n",
    "    root_node = Node(0, 0)  # add root\n",
    "    Tree.add_node(whole_tree, root_node)\n",
    "    for name, group in trees_df_filtered.groupby('sent_name'):\n",
    "        row_ids = trees_df_filtered.index[trees_df_filtered.sent_name == name].to_list()\n",
    "        # temporary dictionary for remapping indices\n",
    "        temp_dict = {key: row_ids[ind] for ind, key in enumerate(group.id.to_list())}\n",
    "        temp_dict[0] = 0\n",
    "        for _, row in group.iterrows():\n",
    "            new_id = temp_dict.get(row['id'])\n",
    "            new_node = Node(new_id, dict_lemmas.get(row['lemma']), row['form'], row['sent_name'])\n",
    "            Tree.add_node(whole_tree, new_node)\n",
    "            new_edge = Edge(temp_dict.get(row['head']), new_id, dict_rel.get(row['deprel']))\n",
    "            Tree.add_edge(whole_tree, new_edge)\n",
    "    return whole_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_children_to_parents(k_2, filtered_groups, whole_tree, curr_height, old_node_new_nodes):\n",
    "    all_parents = set()\n",
    "    for k, v in filtered_groups.items():\n",
    "        for v_id in list(v):\n",
    "            edge_to_curr = Tree.get_edge(whole_tree, v_id)\n",
    "            Tree.get_node(whole_tree, v_id).is_included = True\n",
    "            if edge_to_curr is not None:\n",
    "                parent = edge_to_curr[0].node_from\n",
    "                if max(whole_tree.heights[parent]) > curr_height:\n",
    "                    all_parents.add(parent)\n",
    "                if v_id in old_node_new_nodes.keys():\n",
    "                    lemmas_to_visit = old_node_new_nodes[v_id]\n",
    "                else:\n",
    "                    lemmas_to_visit = [k]\n",
    "                for lemma in lemmas_to_visit:\n",
    "                    label_for_child = str(edge_to_curr[0].weight) + str(lemma)\n",
    "                    if parent not in k_2.keys():\n",
    "                        k_2[parent] = {label_for_child}\n",
    "                    else:\n",
    "                        k_2[parent].add(label_for_child)\n",
    "    return all_parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_additional_children_to_parents(k_2, whole_tree, all_parents):\n",
    "    additional_child_nodes = {}\n",
    "    for parent in all_parents:\n",
    "        for child_id in Tree.get_children(whole_tree, parent):\n",
    "            edge_to_curr = Tree.get_edge(whole_tree, child_id)[0]\n",
    "            child_node = Tree.get_node(whole_tree, child_id)\n",
    "            if not child_node.is_included:\n",
    "                label_for_child = str(edge_to_curr.weight) + str(child_node.lemma)\n",
    "                k_2[parent].add(label_for_child)\n",
    "                child_node.is_included = True\n",
    "                if parent not in additional_child_nodes.keys():\n",
    "                    additional_child_nodes[label_for_child] = child_id\n",
    "                else:\n",
    "                    additional_child_nodes[label_for_child].append(child_id)\n",
    "    return additional_child_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_combinations(k_2, v_id, str_sequence_help, str_sequence_help_reversed, equal_nodes, equal_nodes_mapping):\n",
    "    if len(equal_nodes) > 0:\n",
    "        list_for_combinations = []\n",
    "        prepared_k_2 = set()\n",
    "        included_labels = []\n",
    "        for child_tree in k_2[v_id]:\n",
    "            if child_tree in [item for sublist in list(equal_nodes.values()) for item in sublist] or child_tree in equal_nodes.keys():\n",
    "                if child_tree in equal_nodes_mapping.keys():\n",
    "                    actual_label = equal_nodes_mapping[child_tree]\n",
    "                else:\n",
    "                    actual_label = child_tree\n",
    "                if actual_label not in included_labels:\n",
    "                    list_for_combinations.append(equal_nodes[actual_label])\n",
    "                    included_labels.append(actual_label)\n",
    "            else:\n",
    "                prepared_k_2.add(child_tree)\n",
    "        combinations_repeated = list(product(*(list_for_combinations)))\n",
    "        # test1 = ['10', '11', '12', '13']\n",
    "        # test2 = ['14', '15']\n",
    "        # combinations_repeated = list(product(*([list_for_combinations[0], test1, test2])))\n",
    "        all_combinations = []\n",
    "        if len(prepared_k_2) > 0:\n",
    "            for l in combinations_repeated:\n",
    "                merged = list(l) + list(prepared_k_2)\n",
    "                all_combinations.extend(list(combinations(merged, i)) for i in range(1, len(merged) + 1))\n",
    "        else:\n",
    "            for l in combinations_repeated:\n",
    "                all_combinations.extend(list(combinations(list(l), i)) for i in range(1, len(list(l)) + 1))\n",
    "    else:\n",
    "        list_for_combinations = k_2[v_id]\n",
    "        all_combinations = [list(combinations(list_for_combinations, i)) for i in range(1, len(list_for_combinations) + 1)]\n",
    "    all_combinations_str_joined = set()\n",
    "    for comb in all_combinations:\n",
    "        for tup in comb:\n",
    "            combs = [str(item) for item in sorted(list(map(int, list(tup))))]\n",
    "            joined_label = ''.join(sorted(combs))\n",
    "            if joined_label not in str_sequence_help.keys():\n",
    "                str_sequence_help[joined_label] = combs\n",
    "                str_sequence_help_reversed[tuple(combs)] = joined_label\n",
    "            all_combinations_str_joined.add(joined_label)\n",
    "    return all_combinations_str_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodeid_repeats(filtered_combination_ids, str_sequence_help):\n",
    "    dict_nodeid_comb = {}\n",
    "    for k, v in filtered_combination_ids.items():\n",
    "        for v_i in v:\n",
    "            if v_i in dict_nodeid_comb.keys():\n",
    "                dict_nodeid_comb[v_i].append(str_sequence_help.get(k))\n",
    "            else:\n",
    "                dict_nodeid_comb[v_i] = [str_sequence_help.get(k)]\n",
    "    return dict_nodeid_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_part_new_new(whole_tree, lemma_count, grouped_heights):\n",
    "    classes_subtreeid_nodes = {}\n",
    "    classes_subtreeid_nodes_list = {}\n",
    "    unique_subtrees_mapped_global_subtree_lemma = {}\n",
    "    old_node_new_nodes = {}\n",
    "    equal_nodes_mapping = {}\n",
    "    k_2 = {}  # identifiers of edges of subtrees\n",
    "    lemma_nodeid_dict = {}\n",
    "    for nodes in grouped_heights:\n",
    "        curr_height = nodes[0]\n",
    "        print(curr_height)\n",
    "        start = time.time()\n",
    "        id_lemma_dict = {node.id: node.lemma for node in nodes[1]}\n",
    "        grouped_lemmas = defaultdict(list)\n",
    "        for key, value in id_lemma_dict.items():\n",
    "            grouped_lemmas[value].append(key)\n",
    "        all_parents = add_children_to_parents(k_2, grouped_lemmas, whole_tree, curr_height, old_node_new_nodes)\n",
    "        additional_child_nodes = add_additional_children_to_parents(k_2, whole_tree, all_parents)\n",
    "        for additional_child, child_id in additional_child_nodes.items():\n",
    "            if additional_child not in lemma_nodeid_dict.keys():\n",
    "                lemma_nodeid_dict[additional_child] = {child_id}\n",
    "            else:\n",
    "                lemma_nodeid_dict[additional_child].add(child_id)\n",
    "        for lemma, ids in grouped_lemmas.items():\n",
    "            for v_id in ids:\n",
    "                edge_to_curr = Tree.get_edge(whole_tree, v_id)\n",
    "                if edge_to_curr is not None:\n",
    "                    label_for_child = str(edge_to_curr[0].weight) + str(lemma)\n",
    "                    if label_for_child not in lemma_nodeid_dict.keys():\n",
    "                        lemma_nodeid_dict[label_for_child] = {v_id}\n",
    "                    else:\n",
    "                        lemma_nodeid_dict[label_for_child].add(v_id)\n",
    "        filtered_groups = {k: v for k, v in grouped_lemmas.items() if len(v) > 1}\n",
    "\n",
    "        if curr_height != 0:  # not applicable to leaves, leaves don't have subtrees\n",
    "            for lemma, ids in filtered_groups.items():\n",
    "                combination_ids = {}\n",
    "                str_sequence_help = {}\n",
    "                str_sequence_help_reversed = {}\n",
    "\n",
    "                # generate combinations\n",
    "                for v_id in ids:\n",
    "                    equal_nodes = {}\n",
    "                    # only for duplicating nodes\n",
    "                    children = Tree.get_children(whole_tree, v_id) - whole_tree.created\n",
    "                    # children = list(filter(lambda child: child not in whole_tree.created, Tree.get_children(whole_tree, v_id)))\n",
    "                    for child in children:\n",
    "                        if child in old_node_new_nodes.keys():\n",
    "                            edge_to_child = Tree.get_edge(whole_tree, child)[0]\n",
    "                            child_node = Tree.get_node(whole_tree, child)\n",
    "                            w = str(edge_to_child.weight)\n",
    "                            actual_label = w + str(child_node.lemma)\n",
    "                            if actual_label not in equal_nodes.keys():\n",
    "                                merge = []\n",
    "                                for l in old_node_new_nodes[child]:\n",
    "                                    new_label = w + str(l)\n",
    "                                    merge.append(new_label)\n",
    "                                    equal_nodes_mapping[new_label] = actual_label\n",
    "                                equal_nodes[actual_label] = merge\n",
    "                            else:\n",
    "                                merge = []\n",
    "                                for l in old_node_new_nodes[child]:\n",
    "                                    new_label = w + str(l)\n",
    "                                    merge.append(new_label)\n",
    "                                    equal_nodes_mapping[new_label] = actual_label\n",
    "                                equal_nodes[actual_label].extend(merge)\n",
    "                    all_combinations_str_joined = produce_combinations(k_2, v_id, str_sequence_help,\n",
    "                                                                       str_sequence_help_reversed, equal_nodes,\n",
    "                                                                       equal_nodes_mapping)\n",
    "                    for label in all_combinations_str_joined:\n",
    "                        if label in combination_ids.keys():\n",
    "                            combination_ids[label].append(v_id)\n",
    "                        else:\n",
    "                            combination_ids[label] = [v_id]\n",
    "\n",
    "                filtered_combination_ids = {k: v for k, v in combination_ids.items() if len(v) > 1}\n",
    "                for tree_label, node_list in filtered_combination_ids.items():\n",
    "                    if tree_label not in unique_subtrees_mapped_global_subtree_lemma.keys():\n",
    "                        unique_subtrees_mapped_global_subtree_lemma[tree_label] = lemma_count\n",
    "                        lemma_count += 1\n",
    "                # 16: [['107', '919'], ['208', '919'], ['919'], ['107'], ['208']]\n",
    "                dict_nodeid_comb = get_nodeid_repeats(filtered_combination_ids, str_sequence_help)\n",
    "                for node_id, node_subtrees in dict_nodeid_comb.items():\n",
    "                    existing_node = Tree.get_node(whole_tree, node_id)\n",
    "                    edge_to_curr = Tree.get_edge(whole_tree, node_id)[0]\n",
    "                    children = Tree.get_children(whole_tree, node_id)\n",
    "                    for subtree in node_subtrees:\n",
    "                        subtree_text = str_sequence_help_reversed.get(tuple(subtree))\n",
    "                        subtree_new_label = unique_subtrees_mapped_global_subtree_lemma.get(subtree_text)\n",
    "\n",
    "                        # add new node with a new lemma\n",
    "                        new_node = Tree.copy_node_details(whole_tree, existing_node)\n",
    "                        new_node.lemma = subtree_new_label\n",
    "                        Tree.add_node_to_dict(whole_tree, new_node)\n",
    "\n",
    "                        # add new node to node aliases\n",
    "                        if node_id not in old_node_new_nodes.keys():\n",
    "                            old_node_new_nodes[node_id] = [new_node.lemma]\n",
    "                        else:\n",
    "                            old_node_new_nodes[node_id].append(new_node.lemma)\n",
    "\n",
    "                        # add an edge to it\n",
    "                        edge = Edge(edge_to_curr.node_from, new_node.id, edge_to_curr.weight)\n",
    "                        Tree.add_edge_to_dict(whole_tree, edge)\n",
    "\n",
    "                        # add new node to parent\n",
    "                        parent_subtree_text = str(edge_to_curr.weight) + str(subtree_new_label)\n",
    "                        if parent_subtree_text not in lemma_nodeid_dict.keys():\n",
    "                            lemma_nodeid_dict[parent_subtree_text] = {new_node.id}\n",
    "                        else:\n",
    "                            lemma_nodeid_dict[parent_subtree_text].add(new_node.id)\n",
    "\n",
    "                        subtree_children = []\n",
    "                        children_nodes = {}\n",
    "                        for child in children:\n",
    "                            child_node = Tree.get_node(whole_tree, child)\n",
    "                            str_lemma = str(child_node.lemma)\n",
    "                            child_node_lemma = str(Tree.get_edge(whole_tree, child)[0].weight) + str_lemma\n",
    "                            children_nodes[child_node_lemma] = child_node.id\n",
    "                            children_nodes[str_lemma] = child_node.id\n",
    "                        for subtree_node in subtree:\n",
    "                            if subtree_node not in lemma_nodeid_dict.keys():\n",
    "                                if subtree_node in equal_nodes_mapping.keys():\n",
    "                                    target_child = list(set(lemma_nodeid_dict[equal_nodes_mapping[subtree_node]]) & children)[0]\n",
    "                                else:\n",
    "                                    target_child = children_nodes[subtree_node]\n",
    "                            else:\n",
    "                                intersection = set(lemma_nodeid_dict[subtree_node]) & children\n",
    "                                if len(intersection) == 0:\n",
    "                                    target_child = children_nodes[subtree_node]\n",
    "                                else:\n",
    "                                    target_child = list(intersection)[0]\n",
    "                            subtree_children.append(target_child)\n",
    "\n",
    "                        if len(subtree_children) > 0:\n",
    "                            # add edges to subtree's children from new node\n",
    "                            Tree.add_new_edges(whole_tree, new_node.id, subtree_children)\n",
    "\n",
    "                            # assign class\n",
    "                            if subtree_new_label not in classes_subtreeid_nodes.keys():\n",
    "                                classes_subtreeid_nodes[subtree_new_label] = [new_node.id]\n",
    "                            else:\n",
    "                                classes_subtreeid_nodes[subtree_new_label].append(new_node.id)\n",
    "\n",
    "                            subtree_deep_children = set()\n",
    "                            for subtree_lemma in list(map(lambda x: Tree.get_node(whole_tree, x).lemma, subtree_children)):\n",
    "                                if subtree_lemma in classes_subtreeid_nodes_list.keys():\n",
    "                                    subtree_deep_children.update(classes_subtreeid_nodes_list[subtree_lemma])\n",
    "                            subtree_deep_children.update(subtree_children)\n",
    "                            only_active = subtree_deep_children - whole_tree.inactive\n",
    "                            # only_active = (whole_tree.inactive.symmetric_difference(set_children))&set_children\n",
    "\n",
    "                            if subtree_new_label not in classes_subtreeid_nodes_list.keys():\n",
    "                                classes_subtreeid_nodes_list[subtree_new_label] = only_active\n",
    "                            else:\n",
    "                                classes_subtreeid_nodes_list[subtree_new_label].update(only_active)\n",
    "                            classes_subtreeid_nodes_list[subtree_new_label].add(new_node.id)\n",
    "\n",
    "                    # remove old node and edges to/from it\n",
    "                    Tree.add_inactive(whole_tree, node_id)\n",
    "        print(time.time() - start)\n",
    "    return classes_subtreeid_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-87-5441d0faa27a>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sent_name'] = name + '_' + str(local_counter)\n",
      "<ipython-input-88-7ea0cf5d05b9>:11: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  similar_dict[lemma] = model.most_similar(lemma)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time on constructing the tree: 1.0034382343292236\n",
      "Time on calculating all heights: 0.15526604652404785\n"
     ]
    }
   ],
   "source": [
    "trees_df_filtered = read_data()\n",
    "    # # TEST - тест на первых 3х предложениях\n",
    "trees_df_filtered = trees_df_filtered.head(5015)  # 341 - all? 48 - 3 # 3884 # 5015\n",
    "    # # trees_df_filtered = trees_df_filtered[trees_df_filtered.sent_name == '48554_5']\n",
    "    #\n",
    "    # get all lemmas and create a dictionary to map to numbers\n",
    "dict_lemmas = {lemma: index for index, lemma in enumerate(dict.fromkeys(trees_df_filtered['lemma'].to_list()), 1)}\n",
    "    # get all relations and create a dictionary to map to numbers\n",
    "dict_rel = {rel: index for index, rel in enumerate(dict.fromkeys(trees_df_filtered['deprel'].to_list()))}\n",
    "train_word2vec(trees_df_filtered, dict_lemmas)\n",
    "    #\n",
    "start = time.time()\n",
    "whole_tree = construct_tree(trees_df_filtered, dict_lemmas, dict_rel)\n",
    "print('Time on constructing the tree: ' + str(time.time() - start))\n",
    "    # whole_tree = new_test()\n",
    "Tree.set_help_dict(whole_tree)\n",
    "    # partition nodes by height\n",
    "start = time.time()\n",
    "Tree.calculate_heights(whole_tree)\n",
    "print('Time on calculating all heights: ' + str(time.time() - start))\n",
    "\n",
    "heights_dictionary = {Tree.get_node(whole_tree, node_id): heights for node_id, heights in\n",
    "                          whole_tree.heights.items()}\n",
    "grouped_heights = defaultdict(list)\n",
    "for node, heights in heights_dictionary.items():\n",
    "    for height in heights:\n",
    "        grouped_heights[height].append(node)\n",
    "grouped_heights = sorted(grouped_heights.items(), key=lambda x: x[0])\n",
    "    \n",
    "dict_lemmas_size = max(set(map(lambda x: x.lemma, whole_tree.nodes)))\n",
    "\n",
    "    # classes for partial repeats\n",
    "    \n",
    "#     classes_part = compute_part_new_new(whole_tree, dict_lemmas_size, grouped_heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.18599987030029297\n",
      "1\n",
      "1.7412240505218506\n",
      "2\n",
      "3.5044620037078857\n",
      "3\n",
      "10.251235961914062\n",
      "4\n",
      "16.02889084815979\n",
      "5\n",
      "16.064427852630615\n",
      "6\n",
      "0.9864029884338379\n",
      "7\n",
      "0.25371289253234863\n",
      "8\n",
      "0.3043060302734375\n",
      "9\n",
      "0.09629392623901367\n",
      "10\n",
      "0.08630776405334473\n",
      "11\n",
      "0.000370025634765625\n",
      "12\n",
      "0.0008518695831298828\n",
      "13\n",
      "0.09117484092712402\n",
      "14\n",
      "0.06423592567443848\n",
      "15\n",
      "0.00015783309936523438\n",
      "Time on calculating partial repeats: 49.70806097984314\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "%lprun -f compute_part_new_new compute_part_new_new(whole_tree, dict_lemmas_size, grouped_heights)\n",
    "print('Time on calculating partial repeats: ' + str((time.time() - start) % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-70-69a826bf863d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-70-69a826bf863d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    149     15739    2561829.0    162.8      6.9\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "149     15739    2561829.0    162.8      6.9   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}